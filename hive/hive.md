### 数据分组,取组内第一条数据
原始数据  
```
    val sfdf = Seq(
      (156, 1, 15.8, 50548, 500),
      (157, 3, 152.8, 20548, 600),
      (158, 7, 17.8, 3548, 500),
      (159, 3, 15.8, 40548, 560),
      (160, 4, 15.8, 10548, 500),
      (161, 3, 152.8, 70548, 500),
      (162, 12, 15.8, 30548, 504),
      (163, 2, 15.8, 50348, 520),
      (164, 5, 15.8, 50548, 550),
      (165, 6, 15.8, 52548, 580)
    ).toDF("id", "flight_phase", "vib", "flying_hight", "flying_speed")
```
要求按照flight_phase来分组,组内按照vib来排序,取出每组的第一条记录  
可以用的函数有三个,rank() dense_rank() row_number()  
请看区别,区别主要在于当vib重复时,所打上的序号值,请观察flight_phase为3的记录  
```
    spark.sql("select *,row_number() over(partition by flight_phase order by vib desc) as rk  from t1").show()
    +---+------------+-----+------------+------------+---+
    | id|flight_phase|  vib|flying_hight|flying_speed| rk|
    +---+------------+-----+------------+------------+---+
    |162|          12| 15.8|       30548|         504|  1|
    |156|           1| 15.8|       50548|         500|  1|
    |165|           6| 15.8|       52548|         580|  1|
    |157|           3|152.8|       20548|         600|  1|
    |161|           3|152.8|       70548|         500|  2|
    |159|           3| 15.8|       40548|         560|  3|
    |164|           5| 15.8|       50548|         550|  1|
    |160|           4| 15.8|       10548|         500|  1|
    |158|           7| 17.8|        3548|         500|  1|
    |163|           2| 15.8|       50348|         520|  1|
    +---+------------+-----+------------+------------+---+
    spark.sql("select *,rank() over(partition by flight_phase order by vib desc) as rk  from t1").show()
    +---+------------+-----+------------+------------+---+
    | id|flight_phase|  vib|flying_hight|flying_speed| rk|
    +---+------------+-----+------------+------------+---+
    |162|          12| 15.8|       30548|         504|  1|
    |156|           1| 15.8|       50548|         500|  1|
    |165|           6| 15.8|       52548|         580|  1|
    |157|           3|152.8|       20548|         600|  1|
    |161|           3|152.8|       70548|         500|  1|
    |159|           3| 15.8|       40548|         560|  3|
    |164|           5| 15.8|       50548|         550|  1|
    |160|           4| 15.8|       10548|         500|  1|
    |158|           7| 17.8|        3548|         500|  1|
    |163|           2| 15.8|       50348|         520|  1|
    +---+------------+-----+------------+------------+---+
    spark.sql("select *,dense_rank() over(partition by flight_phase order by vib desc) as rk  from t1").show()
    +---+------------+-----+------------+------------+---+
    | id|flight_phase|  vib|flying_hight|flying_speed| rk|
    +---+------------+-----+------------+------------+---+
    |162|          12| 15.8|       30548|         504|  1|
    |156|           1| 15.8|       50548|         500|  1|
    |165|           6| 15.8|       52548|         580|  1|
    |157|           3|152.8|       20548|         600|  1|
    |161|           3|152.8|       70548|         500|  1|
    |159|           3| 15.8|       40548|         560|  2|
    |164|           5| 15.8|       50548|         550|  1|
    |160|           4| 15.8|       10548|         500|  1|
    |158|           7| 17.8|        3548|         500|  1|
    |163|           2| 15.8|       50348|         520|  1|
    +---+------------+-----+------------+------------+---+
```  
